### 持续交付成熟度模型

#### 概述

持续交付从“持续集成维度”、“质量保证维度”、“环境配置管理维度”、“持续部署维度”5个维度考察其成熟度。

每个维度分为“原始”、“入门”、“初级”、“中级”、“高级”和“专家”6个级别。

目前在各个维度上，行业的平均水平集中在“入门”和“新手”两个级别。

评估时各级别之间不能越级，就是说即使“新手”中个别条目已经做到了，但如果“入门”中有条目没有做到，也只能评为“入门”级。

该模型的主要目的是为了更好地帮助团队认识现状，同时了解改进的方向。该模型是对持续集成主要维度的简单衡量，背后可能有一些并不适合团队的假设。

由于技术和项目的差异性，不同团队达到同一级别需要付出的努力可能差异很大，获得的收益也有区别，因此不适宜利用此模型在团队间进行比较。

##### 原始

缺少流程，对良好的实践不了解，未采纳；团队个别成员偶然地发起改进。

##### 入门

开始尝试建立基本的流程和工程实践能力，但是基于直觉，未系统性地规划，不能完全达到目的。

##### 初级

已定义的标准流程和实践；在软件的开发过程中越来越多地实现自动化。

##### 高级

端到端的流程是可度量，受控的；具备部署过程完全自动化的能力。

##### 持续优化的

关注交付过程的持续优化。

#### 持续集成维度

持续集成现状分析：

1. 如何管理代码？
2. 如何提交并集成代码？
3. 如何管理依赖？
4. 分支策略？
5. 自动化构建的每个步骤？
6. 自动化构建的时间有多长？
7. 构建失败有哪些原因？
8. 是否有本地构建？
9. 提交代码和持续集成的频率？
10. 使用的CI系统是如何配置的？
11. 团队是否遵守统一的持续交付流程？
12. 修复CI的时机及方式？
13. 是否跨流程部署？
14. 持续交付反馈的种类、可视化及响应机制？

##### 原始：

1. 手动方式构建。
2. 构建时间很长，且经常在核心的功能级别发生失败。
3. 没有专用的构建服务器。

##### 入门：

1. 使用版本控制(git、subversion等)。
2. 构建脚本。
3. 定时构建(每日构建或每周构建等)。
4. 专用构建服务器。

##### 初级：

1. 每次代码提交后即运行包含自动化测试的构建过程。
2. 构建过程中的所有代码、测试代码、构建脚本、部署脚本和环境配置等都统一管理在版本控制库中。
3. 只打包一次，能部署到任何环境。
4. 依赖管理仓库(Nexus、Artifactory等)。
5. 构建过程版本化。
6. 构建结果被有效通知团队。
7. 团队所有人都知道代码提交流程(七步提交法)。

##### 中级：

1. 能在本地和集成系统中运行单元测试、集成测试和功能测试。
2. 收集构建的状态和度量数据，对所有人可见。
3. 构建失败立即修复，否则回滚。
4. 基础的持续交付流水线。
5. 充分利用多台机器运行多个构建。

##### 高级

1. 频繁提交，保证持续交付流水线不失败。
2. 运行时间超过限制即构建失败。
3. 在新的环境中，能一键构建完整的开发测试环境并打包部署。
4. 记录构建的趋势指标，持续改进。

##### 专家

1. 代码质量可达到随时部署产品环境。

#### 质量保证维度

质量保证现状分析：

1. 是否有代码编码规范，如何在代码中实施？
2. 有哪些维度的静态代码检查？
3. 有哪些自动化测试，分别运行多长时间？
4. 自动化测试何时写，谁写，如何管理和运行？
5. 测试体系是否符合测试金字塔？
6. 测试覆盖率是多少，是否成为项目交付的指标？
7. 集中测试阶段占交付周期的比例？
8. 提测流程是怎样的，需要多长时间，有哪些人参与？
9. 如何做回归测试？
10. 缺陷修复流程现状？
11. 测试环境是否分离？

##### 原始：

1. 开发完成后才进行测试，并且仅有手工测试。
2. 测试过程时间长，并不能足以建立对产品质量的信心。
3. 单独的测试项目组。
4. 开发人员不做测试。
5. 没有测试脚本。
6. 没有编码规范。

##### 入门：

1. 有部分自动化功能测试(集成测试或功能测试)。
2. 在项目后期集中测试。
3. 利用缺陷跟踪系统管理缺陷。
4. 仅有少量的单元测试，尚未发挥明显作用。
5. 自动化测试只能在特定的环境和数据下运行。

##### 初级：

1. 最小工作单元包含手工测试。
2. 积累一定量的单元测试，团队已从中受益。
3. 构建时运行自动回归测试。
4. 有人工参与的提测过程。
5. 自动化功能测试具备一定数量并起到了一定保障作用。
6. 自动化功能测试全集频繁运行，不少于一天一次。
7. 静态代码检查。

##### 中级：

1. 不同层级的自动化测试发挥质量保障作用，单元测试、接口测试和用户场景测试。
2. 可以在构建中推荐提测版本。
3. 纳入非功能性测试。
4. 自动化提测。

##### 高级：

1. 发布的所有内容都进过了充分的测试，尽可能的遵守测试前移。
2. 自动化测试覆盖率较高，测试工作被有效分散在开发阶段。
3. 手工测试大部分属于探索性测试。

##### 专家：

1. 80%单元测试覆盖率。
2. 自动化测试提供信心十足的质量保证，构建成功后即自动部署。
3. 具有生成环境免疫系统，自动地探测生成部署或运行失败，并自动修复。

####  持续部署维度

持续部署现状分析：

1. 上线流程？
2. 部署文档？
3. 如何判定部署成功？
4. 开发环境和产品环境部署方式是否一致？
5. 有哪些部署脚本，如何管理？
6. 何时部署开发环境，何时部署产品环境，需要多少人参与？
7. 如何回滚部署？
8. 如何部署指定的版本？

##### 原始：

1. 部署流程文档化。

##### 入门：

1. 部分自动化部署，部分手动辅助。

##### 初级：

1. 向测试环境的自动化化部署。
2. 产品环境半自动化部署。

##### 中级：

1. 自动化部署指定的版本。
2. 发布构建为上线候选版本。
3. 不停机部署。

##### 高级：

1. 向生产环境中一键发布，一键回滚。
2. 向生产线部署后的自动化验证。

##### 专家：

1. 一键恢复生产环境。

#### 数据管理

数据管理现状分析：

1. 如何更新数据库？
2. 何时更新数据库？
3. 谁来修改数据库，谁来更新数据库版本？

##### 原始：

1. 数据手动迁移。

##### 入门：

1. 数据库变更通过手工单独执行一个与应用版本相对应的自动化脚本来进行。

##### 初级：

1. 数据库变更，Schema变更和数据迁移的变更，作为部署流水线的一部分。

##### 中级：

1. 能够在所有环境以一致的方式自动化执行  数据库变更脚本在版本控制库中进行版本管理，包括基线和增量脚本。

##### 高级：

1. 总是提供每个版本对应的回滚脚本。
2. 生产环境数据库的升级和回滚可以基于每次部署后的验证自动进行  对数据库的设计和变更遵循演进式原则，小批量持续地对数据库结构进行重构。

##### 专家：

1. 已建立对数据库性能和部署过程的反馈环；并用于数据库迁移过程改进。

#### 环境配置管理维度

环境配置管理现状分析：

1. 环境分配机制？
2. 环境配置方式？
3. 手动分配和配置环境？
4. 在全新的机器上创建完整的工作环境包含哪些步骤？
5. 各开发人员的开发环境是否一致？
6. 各测试环境配置是否一致？
7. 基础设施即代码?

##### 原始：

1. 环境手动分配和配置。

##### 入门：

1. 部分自动化分配和配置环境。
2. 只有少部分人维护环境。

##### 初级：

1. 每个人都能自动申请环境。

##### 中级：

1. 生产环境中的应用配置被版本管理。

##### 高级：

1. 没有仅在团队成员本地保存的任何项目资产。

##### 专家：

1. 开发、测试、生产环境被版本管理，可以一键克隆。

##### 可视化维度

可视化现状分析：

1. 有哪些可视化的数据？
2. 迭代完成的点？
3. 代码的质量报告？
4. 缺陷的数量及趋势？
5. 技术债的数量及趋势？
6. 产品环境部署的频率？
7. 团队每个人的代码贡献量？
8. 构建失败的频率？
9. 运营数据？

##### 原始：

1. 看不到谁在什么时候，为什么目的，完成了什么；没有办法追溯错误的根源。

##### 入门：

1. 具有从需求到发布有限的追溯能力，这种追溯通常是参考多个信息源，有些信息是手动收集的。
2. 追溯错误的根源非常耗时。

##### 初级：

1. 所有人员都能查看到整个构建、测试、部署过程的执行进展和结果，了解到每个环境的部署版本等信息，了解到各生产环境的运行健康度和关键运营数据。
2. 对产品的所有变更可以通过公共的工具集进行追溯，包括对审批和测试结果的跟踪。

##### 中级：

1. 以上构建、测试、部署过程的信息，环境信息，运行健康度，以及运营数据能够随时被所有人看到  对任何元素进行的变更都能够端到端地进行跟踪，从需求，代码，到发布的版本。
2. 自动化地产生完整的发布说明，并且可随时获得任意版本的发布说明。

##### 高级：

1. 频繁地定期进行交付成果演示和回顾。
2. 生产环境回滚应当很少发生，并且是自动进行的。
3. 团队的待办变更项随着时间而减少。

##### 专家：



#### 团队习惯维度

团队习惯现状分析：

1. RD如何定义自己工作完成的含义？
2. 团队签入代码的规范是什么？
3. 是否在签入代码前运行本地构建？
4. 如何确保失败的平台构建有人处理？是签入代码的人处理吗？
5. 构建失败的频率是多少？
6. 团队中谁维护自动化构建脚本？
7. 团队中谁维护CI平台？CI平台有那些权限控制？
8. 团队如何提高每个人的单元测试水平？

##### 原始：

##### 入门：

1. 至少有一个人随时知晓构建状态。
2. 阶段性代码提交习惯。
3. 专人维护持续集成平台和脚本。

##### 初级：

1. 专人看护平台构建状态。
2. 最小工作单元完成后即时合并到目标分支。
3. 所有人知晓当前的构建状态。
4. 构建失败后被及时修复或回滚，失败期间没人提交与修复构建无关的代码。
5. 签入前做本地自动化验证。
6. 团队成员签入代码前做相同的本地验证。
7. 失败构建不过夜。

##### 中级：

1. 失败构建修复时间少于半个小时。
2. 由提交人负责修复失败构建，每个人都关注构建状态。
3. 团队成员都写较为全面的单元测试。
4. 每人每天向目标分支做至少一次对最小工作单元的有效提交。
5. 团队清楚持续集成平台和脚本内容，每个人都可以维护。

##### 高级：

1. 交付团队全员对持续集成平台的稳定构建负责。
2. 交付团队全员负责持续集成脚本开发。

##### 专家：

1. 1小时左右向目标分支做一次对最小工作单元的有效提交，且很少发现构建失败。
